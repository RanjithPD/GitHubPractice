import pandas as pd
import numpy as np 
data = pd.read_csv('lab4.csv')
def entropy(probs): 
    import math     
    return sum( [-prob*math.log(prob, 2) for prob in probs] ) 

def entropy_of_list(a_list): 
    from collections import Counter     
    cnt = Counter(x for x in a_list) 
    
    print("No and Yes Classes:",a_list.name,cnt)     
    num_instances = len(a_list)*1.0     
    probs = [x / num_instances for x in cnt.values()]     
    return entropy(probs) 

total_entropy = entropy_of_list(data['Safe']) 
def information_gain(df,split_attribute_name, target_attribute_name, trace=0):
    print("Information Gain Calculation of ",split_attribute_name)
    df_split = df.groupby(split_attribute_name)
    for name,group in df_split:
        print(name)
        print(group)
        nobs = len(df.index) * 1.0
        df_agg_ent = df_split.agg({target_attribute_name : [entropy_of_list, lambda x: len(x)/nobs] })[target_attribute_name]
        df_agg_ent.columns = ['Entropy', 'PropObservations'] 
        new_entropy = sum( df_agg_ent['Entropy'] * df_agg_ent['PropObservations'] )     
        old_entropy = entropy_of_list(df[target_attribute_name])
        return old_entropy - new_entropy
print('Info-gain for Color is :'+str( information_gain(data, 'Color', 'Safe')),"\n") 
print('\n Info-gain for Hair_type is: ' + str( information_gain(data, 'Hair_type', 'Safe')),"\n") 

print('\n Info-gain for Body_shape is:' + str( information_gain(data , 'Body_shape','Safe')),"\n")